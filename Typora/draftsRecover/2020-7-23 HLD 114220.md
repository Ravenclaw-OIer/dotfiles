---
title: Learning HLD
date: 2020-07-23 10:32:03
tags:
    - Data Structures
mathjax: true
---

HLD, short for "Heavy Light Decomposition", is an approach to data structure problems on trees. The advantages of HLD is that it enabled us to efficiently process queries regarding paths on trees.

<!--more-->

## How is HLD Done?
The essence of HLD is that we dissemble the tree to some paths, so that we can go from vertex $u$ to vertex $v$ by traversing at most $\log n$ paths, by using a data structure to maintain, we can solve many problems in $O(q\log^2n)$ time. 

After the decomposition, it is easy to see that we can reduce the queries formed like "Maintain something on the path from $u$ to $v$" to "Maintain some segments and calculate something within a certain range on a certain path."

We define some terms as follows:

The size of the subtree of $u$ is $sz(u)$.

Consider the edges leading to the children of $u$, we call an edge **heavy** if it leads to a vertex $v$ so that
$$
sz(v) \ge \dfrac{sz(u)}2
$$
In implementation, we can reduce this definition to a simpler form, which will be discussed later. Also, it is obvious that their will be *only one edge* leading to the children of $u$ that is a heavy edge. Other edges are called **light** edges.

We call a path **heavy** if it is solely composed of heavy edges. For simplicity, nodes that are not included in any heavy path are also regarded as heavy paths.

Here is an image for clarification:

![OI-Wiki HLD Example](https://oi-wiki.org/graph/images/hld.png)

## Implementing HLD

The process of implementing HLD includes two steps.

In the first step, we work out the father, depth and heavy son of the node. Pseudo-code follows:
$$
\begin{array}{l}
\text{DFS1}(u) \\
\begin{array}{ll}
1 & u.hson\gets 0 \\
2 & u.size\gets 1 \\
3 & \textbf{for }\text{each }u\text{'s son }v \textbf{ do}\\
4 & \qquad v.dep \gets u.dep + 1\\
5 & \qquad v.fa \gets u\\
6 & \qquad \text{DFS1}(v)\\
7 & \qquad u.size\gets u.size + v.size \\
8 & \qquad \textbf{if }v.size> u.hson.size \textbf{ or } u.hson = 0\textbf{ then}\\
9 & \qquad \qquad u.hson\gets v \\
\end{array}
\end{array}
$$
In the second step, we work out the *top* of the heavy edge a node is in. We can also calculate its position in the array we get by running a so-called heavy edge first DFS. Pseudo-code follows
$$
\begin{array}{l}
tot \gets 0\\
\text{DFS2}(u,t) \\
\begin{array}{ll}
1 & u.top \gets t\\
2 & tot \gets tot + 1\\
3 & u.dfn \gets tot\\
4 & tot.rnk \gets u\\
5 &
3 & \textbf{for }\text{each }u\text{'s son }v \textbf{ do}\\
4 & \qquad v.dep \gets u.dep + 1\\
5 & \qquad v.fa \gets u\\
6 & \qquad \text{DFS1}(v)\\
7 & \qquad u.size\gets u.size + v.size \\
8 & \qquad \textbf{if }v.size> u.hson.size \textbf{ or } u.hson = 0\textbf{ then}\\
9 & \qquad \qquad u.hson\gets v \\
\end{array}
\end{array}
$$
